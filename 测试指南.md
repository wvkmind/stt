# STT 服务各版本测试指南

## 版本概览

| 版本 | 文件 | 引擎 | 速度 | 准确率 | 推荐度 | 状态 |
|------|------|------|------|--------|--------|------|
| **Whisper.cpp** | `server_cpp.py` | C++ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ✅ 推荐 |
| Whisper Medium | `server_streaming.py` | Python | ⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐ | ✅ 稳定 |
| SenseVoice | `server_sensevoice.py` | Python | ⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐ | ⚠️ 慢 |
| SenseVoice ONNX | `server_onnx.py` | ONNX | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐ | ❌ Windows失败 |
| HuggingFace | `server_hf.py` | Transformers | ⭐⭐ | ⭐⭐⭐ | ⭐⭐ | ⚠️ 备用 |

---

## 1. Whisper.cpp 版本 ⭐ 推荐

### 生成原因
- Windows 上 SenseVoice 和 ONNX 都失败
- 需要一个快速、稳定、跨平台的方案
- Whisper.cpp 是 C++ 实现，速度快 5-10 倍

### 特点
- ✅ **速度快**：2 秒转录 30 秒音频
- ✅ **真正流式**：停顿=段落结束，超时=中间结果
- ✅ **跨平台**：Windows/macOS 都支持好
- ✅ **简单**：一行命令安装

### macOS 测试流程

```bash
# 1. 进入项目
cd ~/path/to/stt
git pull

# 2. 激活环境
conda activate stt

# 3. 安装依赖
pip install pywhispercpp opencc-python-reimplemented

# 4. 启动服务
python server_cpp.py

# 5. 观察日志
# 应该看到：
# INFO:__main__:✅ 模型加载完成
# INFO:__main__:C++ 实现，速度提升 5-10 倍！
# INFO:websockets.server:server listening on 0.0.0.0:8765

# 6. 测试客户端连接
# 连接 ws://localhost:8765
# 发送 {"command": "start"}
# 发送音频数据
# 观察实时返回
```

### 预期效果
- 说话 2 秒 → 返回中间结果
- 停顿 1 秒 → 段落结束，开始新段落
- 转录速度：~2 秒/30 秒音频

---

## 2. Whisper Medium 版本（原始版本）

### 生成原因
- 最初的实现，使用 faster-whisper
- 作为稳定的备选方案

### 特点
- ✅ **稳定可靠**
- ✅ **准确率不错**
- ❌ **速度慢**：5-10 秒/30 秒音频

### macOS 测试流程

```bash
# 1. 激活环境
conda activate stt

# 2. 确保依赖已安装
pip install faster-whisper opencc-python-reimplemented

# 3. 启动服务
python server_streaming.py

# 4. 测试
# 连接 ws://localhost:8765
```

### 预期效果
- 分段转录，每段独立
- 速度较慢但准确

---

## 3. SenseVoice 版本

### 生成原因
- 阿里最新模型，中文准确率最高
- 尝试提升中文识别效果

### 特点
- ✅ **中文准确率最高**
- ❌ **加载慢**：首次启动需要 2-3 分钟
- ❌ **转录慢**：比 Whisper 慢

### macOS 测试流程

```bash
# 1. 安装依赖
pip install funasr modelscope torch torchaudio

# 2. 启动服务（耐心等待）
python server_sensevoice.py

# 注意：
# - 首次运行会下载 944MB 模型
# - 模型加载需要 1-2 分钟
# - 会看到大量注册信息（正常）
```

### 预期效果
- 加载慢，但准确率高
- 适合对准确率要求极高的场景

---

## 4. SenseVoice ONNX 版本

### 生成原因
- 尝试用 ONNX 加速 SenseVoice
- C++ 后端，理论上更快

### 特点
- ✅ **理论上快**
- ❌ **Windows 失败**：ONNX 转换错误
- ⚠️ **macOS 未测试**

### macOS 测试流程

```bash
# 1. 安装依赖
pip install funasr-onnx onnxscript

# 2. 尝试启动
python server_onnx.py

# 注意：
# - 首次运行会自动转换 ONNX（5-10 分钟）
# - 可能失败，如果失败就用其他版本
```

### 预期效果
- 如果成功，速度应该比纯 Python 快 3-5 倍
- 如果失败，放弃这个版本

---

## 5. HuggingFace 版本

### 生成原因
- 尝试直接用 HuggingFace transformers
- 作为备用方案

### 特点
- ✅ **标准实现**
- ❌ **速度慢**
- ⚠️ **备用方案**

### macOS 测试流程

```bash
# 1. 安装依赖
pip install transformers accelerate

# 2. 启动服务
python server_hf.py

# 注意：
# - 首次运行会下载模型
# - 速度和 server_streaming.py 类似
```

---

## 推荐测试顺序

### macOS 上的测试顺序

1. **先测 Whisper.cpp**（最推荐）
   ```bash
   python server_cpp.py
   ```
   - 如果成功，就用这个
   - 速度快，效果好

2. **如果需要更高准确率，测 SenseVoice**
   ```bash
   python server_sensevoice.py
   ```
   - 耐心等待加载
   - 准确率最高

3. **备选：Whisper Medium**
   ```bash
   python server_streaming.py
   ```
   - 最稳定的方案

---

## 性能对比（预期）

### Windows 实测

| 版本 | 加载时间 | 转录速度 | 状态 |
|------|---------|---------|------|
| Whisper.cpp | 5秒 | 2秒/30秒音频 | ✅ 成功 |
| Whisper Medium | 10秒 | 5-10秒/30秒音频 | ✅ 成功 |
| SenseVoice | 2-3分钟 | 慢 | ⚠️ 太慢 |
| ONNX | - | - | ❌ 失败 |

### macOS 预期

| 版本 | 加载时间 | 转录速度 | 推荐 |
|------|---------|---------|------|
| Whisper.cpp | 3秒 | 1-2秒/30秒音频 | ⭐⭐⭐⭐⭐ |
| SenseVoice | 1-2分钟 | 3-5秒/30秒音频 | ⭐⭐⭐⭐ |
| Whisper Medium | 5秒 | 3-5秒/30秒音频 | ⭐⭐⭐ |

---

## 流式转录特性

所有版本都支持：

### 触发机制
- **停顿 1 秒** → 段落结束，清空缓冲区
- **持续说话 2 秒** → 返回中间结果，继续累积

### 返回格式
```json
{
  "type": "partial",
  "text": "累积的完整文本",
  "is_final": false
}
```

### 最终结果
```json
{
  "type": "final",
  "text": "完整的所有文本",
  "is_final": true
}
```

---

## 故障排查

### 问题1：模型下载慢
```bash
# 设置 HuggingFace 镜像
export HF_ENDPOINT=https://hf-mirror.com
```

### 问题2：端口被占用
```bash
# 查看端口
lsof -i :8765

# 杀掉进程
kill -9 <PID>
```

### 问题3：依赖冲突
```bash
# 重建环境
conda deactivate
conda remove -n stt --all
conda create -n stt python=3.11 -y
conda activate stt
```

---

## 最终推荐

### 生产环境
- **首选**：`server_cpp.py`（Whisper.cpp）
- **备选**：`server_streaming.py`（Whisper Medium）

### 高准确率需求
- **首选**：`server_sensevoice.py`（SenseVoice）
- **注意**：需要等待加载

### 快速测试
- **首选**：`server_cpp.py`
- **原因**：安装快，启动快，效果好

---

## 测试检查清单

- [ ] git pull 成功
- [ ] conda 环境激活
- [ ] 依赖安装完成
- [ ] 服务启动成功
- [ ] 端口 8765 监听
- [ ] 客户端能连接
- [ ] 能接收音频
- [ ] 能返回结果
- [ ] 停顿触发段落
- [ ] 超时返回中间结果

---

**祝测试顺利！有问题随时喊我。**
